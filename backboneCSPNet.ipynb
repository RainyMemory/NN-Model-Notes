{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.8 64-bit ('envTensorFlow': conda)",
   "display_name": "Python 3.6.8 64-bit ('envTensorFlow': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ef117510eeb4a22464bf884be075799e4233f63c6854f9d9e0da526e12594fce"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# **Pytorch CSPNet implemention**\n",
    "- A simple implemention of CSPDarkNet52 with Pytorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Mish activation\n",
    "- "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mish, self).__init__()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ori_input = x\n",
    "        out = self.softplus(x)\n",
    "        out = self.tanh(out)\n",
    "        out *= ori_input\n",
    "        return out"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## The conv layers for CSPDarkNet\n",
    "- "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPDConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(CSPDConv, self).__init__()\n",
    "        #\n",
    "        self.conv = nn.Conv2d(in_dim, out_dim, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_dim)\n",
    "        self.mish = Mish()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.mish(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Define the residual blocks\n",
    "- the fusion happens before we activate the final output, so the gradient flow is interrupted"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBolck(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, inside_dim=None):\n",
    "        super(ResidualBolck, self).__init__()\n",
    "        # thus the dim will not change in the block\n",
    "        if inside_dim is None:\n",
    "            inside_dim = in_dim\n",
    "        self.conv1 = CSPDConv(in_dim, inside_dim)\n",
    "        self.conv2 = nn.Conv2d(inside_dim, in_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(in_dim)\n",
    "        self.mish = Mish()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ori_input = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out)\n",
    "        # fusion before activation\n",
    "        out += ori_input\n",
    "        out = self.mish(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Contruct the CSPDarkNet\n",
    "- There exits minor differences between the first block and other blocks\n",
    "\n",
    "### CSPDarkNetFirst"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPDarkNetFirst(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, downsample=None):\n",
    "        super(CSPDarkNetFirst, self).__init__()\n",
    "        if downsample is None:\n",
    "            self.downsample = CSPDConv(in_dim, out_dim, kernel_size=3, stride=2, padding=1)\n",
    "        # the input will be transformed into two parts during the first stage\n",
    "        self.trans1 = CSPDConv(in_dim, out_dim)\n",
    "        self.trans2 = CSPDConv(in_dim, out_dim)\n",
    "        # the first residual block\n",
    "        self.resblock = ResidualBolck(out_dim, inside_dim=(out_dim // 2))\n",
    "        # adjust the dim after each concation\n",
    "        self.concat = CSPDConv(out_dim * 2, out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # downsample\n",
    "        x = self.downsample(x)\n",
    "        # transform the x into two parts\n",
    "        x_1 = self.trans1(x)\n",
    "        x_2 = self.trans2(x)\n",
    "        # part 2 will enter the blocks\n",
    "        out = self.resblock(x_2)\n",
    "        # concate the two tensor then adjust the dim\n",
    "        out = torch.cat((x_1, out), dim=1)\n",
    "        out = self.concat(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "### CSPDarkNetBody"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPDarkNetBody(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, block_num, downsample=None):\n",
    "        super(CSPDarkNetBody, self).__init__()\n",
    "        if downsample is None:\n",
    "            self.downsample = CSPDConv(in_dim, out_dim, kernel_size=3, stride=2, padding=1)\n",
    "        # the input will be split into two parts during the first stage\n",
    "        self.trans1 = CSPDConv(in_dim, out_dim // 2)\n",
    "        self.trans2 = CSPDConv(in_dim, out_dim // 2)\n",
    "        # the first residual block\n",
    "        self.resblocks = nn.Sequential(*[ResidualBolck(out_dim // 2) for _ in range(block_num)])\n",
    "        # adjust the dim after each concation, this time the dim should be already aligned\n",
    "        self.concat = CSPDConv(out_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # downsample\n",
    "        x = self.downsample(x)\n",
    "        # transform the x into two parts\n",
    "        x_1 = self.trans1(x)\n",
    "        x_2 = self.trans2(x)\n",
    "        # part 2 will enter the blocks\n",
    "        out = self.resblocks(x_2)\n",
    "        # concate the two tensor then adjust the dim\n",
    "        out = torch.cat((x_1, out), dim=1)\n",
    "        out = self.concat(out)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "### CSPDarkNet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPDarkNet(nn.Module):\n",
    "\n",
    "    def __init__(self, out_dim, blocks, downsample=None):\n",
    "        super(CSPDarkNet, self).__init__()\n",
    "        dim_list = [32, 64, 128, 256, 512, 1024]\n",
    "        # images enter the network\n",
    "        self.conv1 = CSPDConv(in_dim=3, out_dim=dim_list[0], kernel_size=3, stride=1, padding=1)\n",
    "        # the first residual block part\n",
    "        self.resblock1 = CSPDarkNetFirst(in_dim=dim_list[0], out_dim=dim_list[1])\n",
    "        # other residual blocks\n",
    "        self.resblocks = nn.Sequential(*[CSPDarkNetBody(in_dim=dim_list[i], out_dim=dim_list[i+1], block_num=blocks[i-1]) for i in range(1, len(blocks)+1)])\n",
    "        # classcification\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(dim_list[5], out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward propagation\n",
    "        out = self.conv1(x)\n",
    "        out = self.resblock1(out)\n",
    "        out = self.resblocks(out)\n",
    "        out = self.avgpool(out)\n",
    "        # flatten the feature matrix\n",
    "        out = torch.flatten(out)\n",
    "        out = self.fc(out)\n",
    "        out = torch.softmax(out)\n",
    "        return out           "
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Contruct the CSPDarkNet53 and check its structure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CSPDarkNet(\n  (conv1): CSPDConv(\n    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (mish): Mish(\n      (tanh): Tanh()\n      (softplus): Softplus(beta=1, threshold=20)\n    )\n  )\n  (resblock1): CSPDarkNetFirst(\n    (downsample): CSPDConv(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (mish): Mish(\n        (tanh): Tanh()\n        (softplus): Softplus(beta=1, threshold=20)\n      )\n    )\n    (trans1): CSPDConv(\n      (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (mish): Mish(\n        (tanh): Tanh()\n        (softplus): Softplus(beta=1, threshold=20)\n      )\n    )\n    (trans2): CSPDConv(\n      (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (mish): Mish(\n        (tanh): Tanh()\n        (softplus): Softplus(beta=1, threshold=20)\n      )\n    )\n    (resblock): ResidualBolck(\n      (conv1): CSPDConv(\n        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (mish): Mish(\n        (tanh): Tanh()\n        (softplus): Softplus(beta=1, threshold=20)\n      )\n    )\n    (concat): CSPDConv(\n      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (mish): Mish(\n        (tanh): Tanh()\n        (softplus): Softplus(beta=1, threshold=20)\n      )\n    )\n  )\n  (resblocks): Sequential(\n    (0): CSPDarkNetBody(\n      (downsample): CSPDConv(\n        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (trans1): CSPDConv(\n        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (trans2): CSPDConv(\n        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (resblocks): Sequential(\n        (0): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n        (1): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n      )\n      (concat): CSPDConv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n    )\n    (1): CSPDarkNetBody(\n      (downsample): CSPDConv(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (trans1): CSPDConv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (trans2): CSPDConv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (resblocks): Sequential(\n        (0): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n        (1): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n      )\n      (concat): CSPDConv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n    )\n    (2): CSPDarkNetBody(\n      (downsample): CSPDConv(\n        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (trans1): CSPDConv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (trans2): CSPDConv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (resblocks): Sequential(\n        (0): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n        (1): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n      )\n      (concat): CSPDConv(\n        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n    )\n    (3): CSPDarkNetBody(\n      (downsample): CSPDConv(\n        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (trans1): CSPDConv(\n        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (trans2): CSPDConv(\n        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n      (resblocks): Sequential(\n        (0): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n        (1): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n        (2): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n        (3): ResidualBolck(\n          (conv1): CSPDConv(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (mish): Mish(\n              (tanh): Tanh()\n              (softplus): Softplus(beta=1, threshold=20)\n            )\n          )\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (mish): Mish(\n            (tanh): Tanh()\n            (softplus): Softplus(beta=1, threshold=20)\n          )\n        )\n      )\n      (concat): CSPDConv(\n        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (mish): Mish(\n          (tanh): Tanh()\n          (softplus): Softplus(beta=1, threshold=20)\n        )\n      )\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=1024, out_features=800, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "def CSPDarkNet53(out_dim):\n",
    "    return CSPDarkNet(out_dim=out_dim, blocks=[2, 8, 8, 4])\n",
    "\n",
    "mynet = CSPDarkNet53(800)\n",
    "print(mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}